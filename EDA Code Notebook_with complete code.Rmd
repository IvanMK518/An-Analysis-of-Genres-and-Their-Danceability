---
title: "R Notebook"
output: html_notebook
---

Components of Analysis (from canvas, basically the rubric for the assignment)
* Introducing the dataset (including its source, scope, and any ethical considerations) framed by the purpose of the exploratory analysis, anticipating any subsetting or re-ordering of the data for your interests
* Reading the data into R in a tabular format, identifying, subsetting, and renaming the variables for your use
* Forming the core data frame that you'll be working from by reshaping and summarizing the data, storing new data frames in memory where appropriate
* Cleaning the data according to your purpose for the dataset
* Plotting distributions of your data
* Calculating basic statistical metrics like central tendency measures
* Some light correlational analysis/visualization of key variables.
* A look forward to what further questions the analysis suggests and what it enables

# Music Dataset : 1950 to 2019

## Introduction

Music is a core human experience, a fundamental part of our evolution. Music is an outlet for people to express and communicate with others. Some produce it and more consume and share it. It’s part of life that defines many people’s identities and helps to emphasize moods, whether uplifting or depressive, energetic or calming. The purpose in utilizing music data helps to understand how people’s behaviors over time are reflected and impact the music we hear. Though not necessarily simply a matter of change over time, we can discover what aspects are critical characteristics of each specific genre of music and its era of release through musical metadata. “There are several works involving musical lyrics and topic modeling, one in specific and very common used is the Latent Dirichlet Allocation (LDA) [Blei 2003]” (Misael, Luan, et al., 2020). LDA is a probabilistic model used to find latent semantic topics in collections of texts such as lyrics. We can cite the LyricsRadar [Sasaki 2014] which is a system based on latent topics of lyrics generated by LDA that enables a user to visualize the music topics interactively. LDA can also be applied to identify sentiments from songs through the lyrics just as audio analysis can [Sharma 2011, Dakshina 2013]. Using methods of creating data out of music using LDA provides a baseline for how we organize and characterize music for algorithms, such as one that you may see on Spotify. LDA is the start of how we can use statistical data to show how playlists are chosen by users, what features influence musical choices, and in some cases predict hits. Using audio data scrapped using Echo Nest® API integrated engine with spotipy Python’s package. The spotipy API permits the user to search for specific genres, artists, songs, release dates, etc. To obtain the lyrics we used the Lyrics Genius® API as base URL for requesting data based on the song title and artist name. Of the numerous song characteristics shown by the publicly available spotify based dataset, we chose to use a select few for in depth analysis in our quest to find what genres of music are most associated with dancing and danceability. Diving deeper, we wanted to understand what characteristics of a song made one more or less danceable. 


The first step taken to begin the process of  filtering of data from this public music data set, was to install the Rstudio packages and libraries shown below:
```{r
# Set CRAN mirror and install necessary packages
options(repos = c(CRAN = "https://cran.rstudio.com"))

install.packages("evaluate")
install.packages("renv")
install.packages("tidyverse")
install.packages("ggplot2")
install.packages("dplyr")
install.packages("magrittr")

# Snapshot, restore, and hydrate renv environment
renv::snapshot()
renv::restore()
renv::hydrate()

# Load necessary libraries
library(tidyverse)
library(readr)
library(ggplot2)
library(dplyr)
library(magrittr)
```
The code snippet below is used in an R Markdown document to control the global options for all code chunks in the document. When echo = True, the code is shown with the corresponding output which makes it easier for authors and readers to see what the code is producing.
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


A preliminary step to filtering the data set is to test R and our music.csv file. This code snippet prints the first 6 observations, just to be sure we are working with the correct data set as R working directories may get crowded. 
```{r}
head(music)
```
A few more preliminary steps in testing R and confirming the csv file are functioning are to play around with the csv file. 
```{r}
str(music)

print(names(music))

summary(music)
```
First, Using the "str" function helps us see the structure of the data set in that we have #31 columns with quantitative (numerical) and qualitative data such as a certain characteristic. The "print(names(music))" and "summary" functions just provide an organized view of the column titles and the sample characteristics (quartiles, median, and mode) of each column respectively. 




A data set with so much qualitative data may be initially difficult to process, but if the qualitative data is assigned numerical values, analyzing the data can be done with concrete methodology that can be replicated. In order to quantify and assign values to a seemingly qualitative characteristic such as lyrical theme, the creators of the public data set used:

EQUATION 1: 1. similarity = cos(Θ) = ϕi · ϕj /(ϕi ϕj)

This equation would compute a number between 0 and 1 that would effectively act as a piece of raw data representing a lyrical characteristic or theme of a song. According to the creators of the data set:

"We evaluated the cosine distance, Eqn. (1), of words per topic using a 100-dimension GloVe word embedding [Pennington 2014] vector representation. To visualize the best number of words to represent each topic, we select every word proportion per topic k represented by ϕk distribution by the most frequent term in that topic to the rarest term.For each topic, we have chosen the first 10 words of ϕK and computed the cosine distance for every pair of their embedding vectors and stored the mean result in a variable gk,10. We repeated the same methodology for the first 11 to 25 words of ϕk in each topic k calculating the mean cosine distance of the word embeddings. Based on those criteria, we select an appropriate number of words to represent each topic that maximizes the mean cosine similarity. Each topic received a label based on the main subject of the selected words. A stop word list was used to exclude common English words. The stop word list used is built-in Scikit-learn." (Misael, Luan, et al., 2020)

In our quest to find which songs and corresponding genres from the dataset were most danceable we considered a few song characteristics:

  * Acousticness: Presence of acoustic instruments
  * Danceability: how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat        strength, and overall regularity
  * Loudness: The average loudness in decibels (dB) across the entire track
  * Instrumentalness: A high value describes whether a track contains fewer vocals
  * Valence: High (low) values means that the track is more happy, euphoric (sad, angry)
  * Energy: Measures intensity and activity of music. Energetic tracks will be fast, loud and noisy
Each characteristic as mentioned would be assigned a value between 0-1 based on equation 1 (shown above).




The code snippet just below is selecting specific columns from our intitial music.csv data set and assigning them to a new data frame called "data" that includes only these selected columns (consisting of data necessary for this coding and analysis).
```{r}
data <- music[ ,c("genre", "loudness", "energy", 
"danceability", "feelings", "instrumentalness", "lyrics")]
```

In this small code chunk below, the median danceability by genre is found from the data set. 
```{r}
median_danceability_by_genre <- data %>%
  group_by(genre) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

print(median_danceability_by_genre)
```
The first line is creating a data frame called "median_danceability_by_genre" from the "data" data frame and this pipe operator (%>%) allows the author to chain multiple functions together in a clear and readable way. The data frame data is passed to the next function in the chain. Then using the "group_by" function the data frame is grouped by the genre column. This means that subsequent operations will be performed separately for each genre. The 2nd to last line creates a new data frame containing summary statistics using "summmarise." In this case, it will create one row per genre. "median(danceability, na.rm = TRUE)" will calculates the median of the danceability column for each genre group from the data set. The na.rm = TRUE argument ensures that any NA (missing) values are removed before calculating the median. Finally, the new data frame is printed, showing a 2 column chart with 7 rows. Each row should show a genre in one column with a corresponding median danceability score in the other.


```{r}
# Create a bar chart of median danceability by genre
ggplot(median_danceability_by_genre, aes(x = genre, y = median_danceability)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Genre",
       x = "Genre",
       y = "Median Danceability")
```

```{r}
library(dplyr)

# Calculate median danceability by genre
median_danceability_by_feeling <- data %>%
  group_by(feelings) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Print the median danceability by genre
print(median_danceability_by_feeling)
```

```{r}
library(readr)
library(ggplot2)

# Bins to condense data of musical feel 
num_bins <- 20 
data <- data %>%
  mutate(feeling_bin = cut(feelings, breaks = num_bins))

# Calculate median danceability by feel of music
median_danceability_by_feeling_bin <- data %>%
  group_by(feeling_bin) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Bar chart of median danceability by feel
ggplot(median_danceability_by_feeling_bin, aes(x = feeling_bin, y = median_danceability)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Feel",
       x = "Feel",
       y = "Median Danceability")
```

```{r}
library(dplyr)

# Calculate median danceability by genre
median_danceability_by_instrumentalness <- data %>%
  group_by(instrumentalness) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Print the median danceability by genre
print(median_danceability_by_instrumentalness)
```

```{r}
# Create bins for the instrumentalness variable
num_bins <- 20 
data <- data %>%
  mutate(instrumentalness_bin = cut(instrumentalness, breaks = num_bins))

# Calculate median danceability by instrumentalness bin
median_danceability_by_instrumentalness <- data %>%
  group_by(instrumentalness_bin) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Bar chart of median danceability by instrumentality
ggplot(median_danceability_by_instrumentalness, aes(x = instrumentalness_bin, y = median_danceability)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Instrumentality",
       x = "Instrumentality",
       y = "Median Danceability")
```

```{r}
# Bins for condensing data inthe feelings and instrumentalness variables
num_bins_feelings <- 2
num_bins_instrumentalness <- 2

data <- data %>%
  mutate(feeling_bin = cut(feelings, breaks = num_bins_feelings),
         instrumentalness_bin = cut(instrumentalness, 
         breaks = num_bins_instrumentalness))

# Calculate median danceability by genre, feelings bin, and instrumentalness bin
median_danceability_by_genre_feeling_instrumentalness <- data %>%
  group_by(genre, feeling_bin, instrumentalness_bin) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Create a bar chart of median danceability by genre, feelings bin, and instrumentalness bin
ggplot(median_danceability_by_genre_feeling_instrumentalness, aes(x = interaction(feeling_bin, 
instrumentalness_bin), y = median_danceability, fill = genre)) +
  geom_bar(stat = "identity", position = "dodge") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Genre, Feeling, and Instrumentalness",
       x = "Feeling and Instrumentalness",
       y = "Median Danceability",
       fill = "Genre")
```
```{r}
# Bins for condensing the data in feelings and instrumentalness variables
num_bins_feelings <- 4
num_bins_instrumentalness <- 4

data <- data %>%
  mutate(feeling_bin = cut(feelings, breaks = num_bins_feelings),
         instrumentalness_bin = cut(instrumentalness, 
         breaks = num_bins_instrumentalness))

# Calculate median danceability by genre, feelings bin, and instrumentalness bin
median_danceability_by_genre_feeling_instrumentalness <- data %>%
  group_by(genre, feeling_bin, instrumentalness_bin) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

# Scatter plot with wider variety of data points
ggplot(median_danceability_by_genre_feeling_instrumentalness, aes(x = interaction(feeling_bin, 
instrumentalness_bin), y = median_danceability, color = genre)) +
  geom_point(size = 3) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Genre, Feeling, and Instrumentalness",
       x = "Feeling and Instrumentalness",
       y = "Median Danceability",
       color = "Genre")
```
```{r}
library(dplyr)

# Calculate median danceability by decibel level
median_danceability_by_loudness <- data %>%
  group_by(loudness) %>%
  summarise(median_danceability = median(danceability, na.rm = TRUE))

print(median_danceability_by_loudness)
```

```{r}
library(readr)
library(ggplot2)

# Bar chart of median danceability by decibel level
ggplot(median_danceability_by_loudness, aes(x = loudness, y = median_danceability)) +
  geom_bar(stat = "identity", fill = "blue") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title = "Median Danceability by Loudness",
       x = "Loudness (Db)",
       y = "Median Danceability")
```
Conclusions and findings 

Using this example of finding danceable music will provide a simple answer to what one could put on a playlist for a daneable mood, but the framework for finding this data is far more applicable than just finding what songs and corresponding genres are most danceable and why. 




Below are what we notice about the music dataset after some basic exploration:

* The head() function gives us a close look at the rows and the columns of the dataset. The rows tell us that the dataset contains 28,372 songs, with each row corresponding to one specific song. The first seven columns provide each listed song with (I'm not sure what the first row is about, maybe we can delete it) the artist's name, the song's name, the release date, the genre, a few lines of lyrics, and the length of the song (measured in seconds). 

* Aside from the above mentioned 7 columns that provide the basic identification of the listed songs, the remaining columns meansure each song on 24 different dimensions. Some examples include (the following is from the paper based on this dataset, I will paraphrase them later)
  * Acousticness: Presence of acoustic instruments
  * Danceability: how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity
  * Loudness: The average loudness in decibels (dB) across the entire track
  * Instrumentalness: A high value describes whether a track contains fewer vocals
  * Valence: High (low) values means that the track is more happy, euphoric (sad, angry)
  * Energy: Measures intensity and activity of music. Energetic tracks will be fast, loud and noisy

* The str() function then gives us the variable types included in the dataset. The majority of the variables possess the form of numbers, followed by some characters. Finally, the summary() function provides us with all the statistical measurements of the variables. (We can further discuss some interesting tendency/outliers here, leading to the question we wanna prpose for further exploration.)